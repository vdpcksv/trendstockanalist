# -*- coding: utf-8 -*-
from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse, PlainTextResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import json
import FinanceDataReader as fdr
from contextlib import asynccontextmanager
from functools import lru_cache
from apscheduler.schedulers.background import BackgroundScheduler
from sqlalchemy.orm import Session
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm

from database import engine, get_db
import models
import schemas
import auth

# Create all tables in the database (this is safe if they already exist)
models.Base.metadata.create_all(bind=engine)

# --- Global Cache ---
# Stores the results of slow web scraping tasks to serve instantly
cache_data = {
    "money_flow": [],
    "theme_list": pd.DataFrame(),
}



HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def get_money_flow_data():
    """Npay ì¦ê¶Œ êµ­ë‚´ì¦ì‹œ ë©”ì¸ í˜ì´ì§€ì—ì„œ íˆ¬ììë³„ ë™í–¥ì„ íŒŒì‹±í•´ì˜µë‹ˆë‹¤."""
    url = "https://finance.naver.com/sise/"
    try:
        response = requests.get(url, headers=HEADERS, timeout=5)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ íŒŒì‹± ë¡œì§ (ê¸°ì¡´ app.py ì°¸ê³ )
        flow_table = soup.select_one("div.box_type_m iframe") 
        if not flow_table:
            # ê¸°ë³¸ ëª¨ì˜ ë°ì´í„° ë¦¬í„´ (í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ)
            return _get_mock_flow_data()
            
        # ì •í™•í•œ iframe srcë¥¼ ì¶”ì í•˜ê±°ë‚˜ ë”ë¯¸ë°ì´í„° ë°˜í™˜
        return _get_mock_flow_data()
    except Exception as e:
        print(f"Flow data error: {e}")
        return _get_mock_flow_data()

def _get_mock_flow_data():
    today = datetime.now().strftime("%Y-%m-%d")
    return [
        {"Date": today, "ê°œì¸": -1500, "ì™¸êµ­ì¸": 2000, "ê¸°ê´€": -500},
        {"Date": "2026-02-20", "ê°œì¸": 500, "ì™¸êµ­ì¸": -800, "ê¸°ê´€": 300},
        {"Date": "2026-02-19", "ê°œì¸": -200, "ì™¸êµ­ì¸": 1200, "ê¸°ê´€": -1000},
        {"Date": "2026-02-18", "ê°œì¸": 1800, "ì™¸êµ­ì¸": -1500, "ê¸°ê´€": -300},
        {"Date": "2026-02-17", "ê°œì¸": 100, "ì™¸êµ­ì¸": 500, "ê¸°ê´€": -600},
    ]

# --- Background Task Functions ---
def fetch_and_cache_data():
    """Background task that periodically fetches scraping data."""
    try:
        print(f"[{datetime.now()}] Fetching background data...")
        flow_data = get_money_flow_data()
        theme_data = get_theme_list()
        
        # Safe update of cache
        if flow_data:
            cache_data["money_flow"] = flow_data
        if not theme_data.empty:
            cache_data["theme_list"] = theme_data
            
        print(f"[{datetime.now()}] Data fetch complete. Cached {len(flow_data)} flow records and {len(theme_data)} themes.")
    except Exception as e:
        print(f"Background fetch error: {e}")

# --- Application Lifespan Events ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup: Initialize scheduler and run immediately
    scheduler = BackgroundScheduler()
    # Execute immediately on boot
    fetch_and_cache_data() 
    # Schedule to run every 10 minutes
    scheduler.add_job(fetch_and_cache_data, 'interval', minutes=10)
    scheduler.start()
    
    yield # Hand control back to FastAPI
    
    # Shutdown: Stop scheduler
    scheduler.shutdown()

app = FastAPI(title="Trend-Lotto Invest", lifespan=lifespan)

# Serve static files (CSS, JS) securely mapped to /static
app.mount("/static", StaticFiles(directory="static"), name="static")

# Initialize Jinja2 templates directory
templates = Jinja2Templates(directory="templates")

@app.get("/", response_class=HTMLResponse)
async def read_dashboard(request: Request):
    # Use cached data instead of real-time scraping
    flow_data = cache_data.get("money_flow", [])
    if not flow_data:
        flow_data = _get_mock_flow_data()
    
    # Generate Insight
    last_record = flow_data[0]
    last_foreign = last_record["ì™¸êµ­ì¸"]
    last_instit = last_record["ê¸°ê´€"]
    
    if last_foreign > 0 and last_instit > 0:
        insight = f"ìµœê·¼ ì˜ì—…ì¼ ê¸°ì¤€ ì™¸êµ­ì¸({last_foreign}ì–µ)ê³¼ ê¸°ê´€({last_instit}ì–µ)ì´ ì–‘ë§¤ìˆ˜ë¥¼ ê¸°ë¡í•˜ë©° ìš°í˜¸ì ì¸ ì‹œì¥ í™˜ê²½ì´ ì¡°ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
    elif last_foreign > 0:
        insight = f"ê¸°ê´€ì€ ë§¤ë„ ìš°ìœ„ì´ë‚˜, ì™¸êµ­ì¸ì´ {last_foreign}ì–µ ì› ìˆœë§¤ìˆ˜í•˜ë©° ì§€ìˆ˜ë¥¼ ë°©ì–´í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    elif last_instit > 0:
        insight = f"ì™¸êµ­ì¸ì€ ë§¤ë„ ìš°ìœ„ì´ë‚˜, ê¸°ê´€ì´ {last_instit}ì–µ ì› ìˆœë§¤ìˆ˜í•˜ë©° ì‹œì¥ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤."
    else:
        insight = "í˜„ì¬ ê¸°ê´€ê³¼ ì™¸êµ­ì¸ ëª¨ë‘ ì–‘ë§¤ë„ë¥¼ ê¸°ë¡ ì¤‘ì…ë‹ˆë‹¤. ìˆ˜ê¸‰ ë³´ìˆ˜ì  ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
    return templates.TemplateResponse(
        request=request, name="dashboard.html",
        context={
            "flow_data_json": json.dumps(flow_data),
            "flow_data": flow_data,
            "insight": insight
        }
    )

def get_seasonality_data():
    """ëŒ€í‘œ ì„¹í„°ë³„ ìµœê·¼ 10ë…„ê°„ì˜ ì›”ë³„ ìŠ¹ë¥  ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # (ì‹¤ ì„œë²„ í™˜ê²½ì—ì„œëŠ” fdrì„ í™œìš©í•´ ì‹¤ì‹œê°„ ì—°ì‚°í•˜ì§€ë§Œ, ì—¬ê¸°ì„  Prototype ì†ë„ë¥¼ ìœ„í•´ Mock Data ì‚¬ìš©)
    return {
        "ë°˜ë„ì²´": [60, 50, 40, 70, 55, 45, 65, 80, 50, 60, 70, 85],
        "2ì°¨ì „ì§€": [70, 60, 50, 45, 80, 75, 55, 60, 45, 50, 65, 90],
        "ë°”ì´ì˜¤": [40, 45, 55, 60, 50, 65, 70, 45, 80, 75, 60, 55],
        "ê¸ˆìœµ": [55, 60, 70, 80, 75, 65, 50, 45, 40, 50, 60, 65],
        "ìë™ì°¨": [50, 55, 65, 70, 60, 50, 45, 55, 65, 80, 75, 70],
        "ê²Œì„/ì—”í„°": [45, 50, 55, 60, 70, 80, 85, 75, 65, 55, 50, 45]
    }

@app.get("/seasonality", response_class=HTMLResponse)
async def read_seasonality(request: Request):
    season_data = get_seasonality_data()
    # DataFrameìœ¼ë¡œ ë³€í™˜ í›„ Heatmapìš© Z(ìŠ¹ë¥ ), X(ì›”), Y(ì„¹í„°) ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    df_hm = pd.DataFrame(season_data).T 
    df_hm.columns = [f"{i}ì›”" for i in range(1, 13)]
    
    z_data = df_hm.values.tolist()
    y_labels = df_hm.index.tolist()
    x_labels = df_hm.columns.tolist()
    
    current_month_idx = datetime.now().month - 1
    
    return templates.TemplateResponse(
        request=request, name="seasonality.html",
        context={
            "z_data": json.dumps(z_data),
            "x_labels": json.dumps(x_labels),
            "y_labels": json.dumps(y_labels),
            "current_month_idx": current_month_idx
        }
    )

def get_theme_list():
    """Npay ì¦ê¶Œ êµ­ë‚´ì¦ì‹œ í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•´ì˜µë‹ˆë‹¤."""
    url = "https://finance.naver.com/sise/theme.naver"
    try:
        response = requests.get(url, headers=HEADERS, timeout=5)
        response.raise_for_status()
        response.encoding = 'cp949'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        themes = []
        table = soup.select_one('.type_1.theme')
        if not table:
            return pd.DataFrame()
            
        for tr in table.select('tr'):
            col_name = tr.select_one('td.col_type1 a')
            col_rate = tr.select_one('td.col_type2')
            
            if col_name and col_rate:
                link = "https://finance.naver.com" + col_name['href']
                themes.append({
                    "í…Œë§ˆëª…": col_name.text.strip(),
                    "ë“±ë½ë¥ (%)": col_rate.text.strip().replace('%', ''),
                    "ë§í¬": link
                })
        
        return pd.DataFrame(themes).head(20) if themes else pd.DataFrame()
    except Exception as e:
        print(f"Theme parsing error: {e}")
        return pd.DataFrame()

def get_theme_top_stocks(theme_url):
    """í•´ë‹¹ í…Œë§ˆ í˜ì´ì§€ ë‚´ ìƒìœ„ ë“±ë½ë¥  ì¢…ëª© 5ê°œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    try:
        response = requests.get(theme_url, headers=HEADERS, timeout=5)
        response.raise_for_status()
        response.encoding = 'cp949'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        stocks = []
        # í…Œë§ˆ í˜ì´ì§€ ë‚´ í¸ì… ì¢…ëª© í…Œì´ë¸”
        table = soup.select_one('.type_5 tbody')
        if not table:
            return pd.DataFrame()
            
        for idx, tr in enumerate(table.select('tr')):
            if idx > 10: break # ìµœëŒ€ 10ê°œë§Œ íƒìƒ‰ (ìƒìœ„ 5ê°œë¥¼ ìœ„í•´ ì—¬ìœ ë¶„ í™•ë³´)
            name_tag = tr.select_one('.name a')
            price_tag = tr.select_one('.number')
            rate_tag = tr.select('.number')
            
            if name_tag and price_tag and len(rate_tag) >= 3:
                # rate_tag êµ¬ì¡°: í˜„ì¬ê°€, ì „ì¼ë¹„, ë“±ë½ë¥  ...
                stocks.append({
                    "ì¢…ëª©ëª…": name_tag.text.strip(),
                    "í˜„ì¬ê°€": price_tag.text.strip(),
                    "ë“±ë½ë¥ ": rate_tag[2].text.strip().replace('\n', '').replace('\t', '')
                })
                if len(stocks) >= 5:
                    break
                    
        return pd.DataFrame(stocks)
    except Exception as e:
        print(f"Detailed Theme parsing error: {e}")
        return pd.DataFrame()

@app.get("/themes", response_class=HTMLResponse)
async def read_themes(request: Request, theme: str = None):
    # Use cached theme list
    df_themes = cache_data.get("theme_list", pd.DataFrame())
    if df_themes.empty:
        context = {"error": "í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
        return templates.TemplateResponse(request=request, name="themes.html", context=context)
    
    themes_data = df_themes.to_dict('records')
    context = {"themes": themes_data, "selected_theme_data": None, "stocks_data": None, "ai_comment": None}
    
    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ ì„ íƒëœ í…Œë§ˆì˜ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
    if theme:
        selected_row = df_themes[df_themes['í…Œë§ˆëª…'] == theme]
        if not selected_row.empty:
            selected_info = selected_row.iloc[0]
            context["selected_theme_data"] = selected_info.to_dict()
            
            # ì£¼ë„ ì¢…ëª© ì¶”ì¶œ
            df_stocks = get_theme_top_stocks(selected_info['ë§í¬'])
            if not df_stocks.empty:
                context["stocks_data"] = df_stocks.to_dict('records')
                
            # AI ì‹œë‚˜ë¦¬ì˜¤ ì§„ë‹¨ ë¡œì§
            try:
                rate_val = float(selected_info['ë“±ë½ë¥ (%)'].replace('+', ''))
                if rate_val > 3.0:
                    ai_title = "ğŸ“ˆ ë§¤ìš° ê°•í•œ ìê¸ˆ ìœ ì…"
                    ai_desc = "í˜„ì¬ ì‹œì¥ ì£¼ë„ í…Œë§ˆë¡œ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€ì¥ì£¼ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ì§§ì€ ë‹¨ê¸° íŠ¸ë ˆì´ë”© ì ‘ê·¼ì´ ìœ íš¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                elif rate_val > 0:
                    ai_title = "âš–ï¸ ì™„ë§Œí•œ ìƒìŠ¹ì„¸"
                    ai_desc = "ì¡°ìš©íˆ ìš°ìƒí–¥ ì¤‘ì¸ í…Œë§ˆì…ë‹ˆë‹¤. í–¥í›„ ëª¨ë©˜í…€(ë‰´ìŠ¤/ì •ì±…) ë°œìƒ ì‹œ ì¶”ê°€ ìŠˆíŒ…ì˜ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
                else:
                    ai_title = "ğŸ“‰ ì¡°ì • ì¤‘ (ëˆŒë¦¼ëª©)"
                    ai_desc = "í˜„ì¬ ë§¤ìˆ˜ì„¸ê°€ ì•½í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¨ê¸° ê¸‰ë½ í›„ ê³„ì ˆì  ë°˜ë“±ì„ ë…¸ë¦¬ëŠ” ì¤‘ê¸° ê´€ì ì˜ ë¶„í•  ë§¤ìˆ˜ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤."
                
                context["ai_comment"] = {"title": ai_title, "desc": ai_desc}
            except:
                pass

    return templates.TemplateResponse(request=request, name="themes.html", context=context)

def calculate_technical_indicators(df):
    """(ê¸°ì¡´ app.py ë¡œì§) ë‹¨ìˆœ ì´ë™í‰ê· , ë³¼ë¦°ì € ë°´ë“œ, RSI ê³„ì‚°"""
    df = df.copy()
    # 5/20/60ì¼ ì´ë™í‰ê· 
    df['MA5'] = df['Close'].rolling(window=5).mean()
    df['MA20'] = df['Close'].rolling(window=20).mean()
    df['MA60'] = df['Close'].rolling(window=60).mean()

    # ë³¼ë¦°ì € ë°´ë“œ (20ì¼, 2 standard deviations)
    df['BB_MB'] = df['MA20']
    df['BB_STD'] = df['Close'].rolling(window=20).std()
    df['BB_UPPER'] = df['BB_MB'] + (df['BB_STD'] * 2)
    df['BB_LOWER'] = df['BB_MB'] - (df['BB_STD'] * 2)

    # ê·¹ë‹¨ì  ë³¼ë¦°ì € ë°´ë“œ (20ì¼, 3 standard deviations)
    df['BB_UPPER_EXT'] = df['BB_MB'] + (df['BB_STD'] * 3)
    df['BB_LOWER_EXT'] = df['BB_MB'] - (df['BB_STD'] * 3)

    # RSI (14ì¼)
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))

    return df

@lru_cache(maxsize=1)
def get_krx_stock_listing():
    return fdr.StockListing('KRX')

def resolve_ticker(query: str):
    query = query.strip()
    if query.isdigit() and len(query) == 6:
        return query
    
    try:
        df = get_krx_stock_listing()
        matches = df[df['Name'] == query]
        if not matches.empty:
            return matches.iloc[0]['Code']
    except Exception as e:
        print(f"Error resolving ticker: {e}")
    return query

def get_stock_fundamentals(ticker: str):
    """Scrapes essential fundamental data using Naver mobile JSON API for stability."""
    url = f"https://m.stock.naver.com/api/stock/{ticker}/finance/annual"
    try:
        res = requests.get(url, headers=HEADERS, timeout=5)
        res.raise_for_status()
        data = res.json()
        
        headers = [item['title'] for item in data['financeInfo']['trTitleList']]
        parsed_data = {}
        
        target_indices = {
            0: "ë§¤ì¶œì•¡",
            1: "ì˜ì—…ì´ìµ",
            2: "ë‹¹ê¸°ìˆœì´ìµ",
            8: "ë¶€ì±„ë¹„ìœ¨",
            7: "ROE(ì§€ë°°ì£¼ì£¼)",
            12: "PER(ë°°)",
            14: "PBR(ë°°)"
        }
        
        row_list = data['financeInfo']['rowList']
        header_keys = [item['key'] for item in data['financeInfo']['trTitleList']]
        
        for idx, key_name in target_indices.items():
            if idx < len(row_list):
                row = row_list[idx]
                vals = []
                for hk in header_keys:
                    vals.append(row['columns'].get(hk, {}).get('value', '-'))
                parsed_data[key_name] = vals
                
        return {"headers": headers, "data": parsed_data}
    except Exception as e:
        print(f"Error fetching fundamentals: {e}")
        return None

def get_news_sentiment(ticker: str):
    """Fetches recent news from Naver Mobile API and performs keyword-based sentiment analysis."""
    url = f"https://m.stock.naver.com/api/news/stock/{ticker}?pageSize=15"
    
    pos_keywords = ['ìƒìŠ¹', 'ê¸‰ë“±', 'ëŒíŒŒ', 'í‘ì', 'ìˆ˜ì£¼', 'í˜¸ì¡°', 'MOU', 'ê°•ì„¸', 'ì²´ê²°', 'ìµœëŒ€', 'ì‹ ê³ ê°€', 'ì„±ì¥', 'ê¸°ëŒ€', 'ìˆ˜í˜œ', 'ë°˜ë“±']
    neg_keywords = ['í•˜ë½', 'ê¸‰ë½', 'ì ì', 'ìš°ë ¤', 'ìˆ˜ì‚¬', 'ì•…ì¬', 'ì•½ì„¸', 'ì‹ ì €ê°€', 'ë¯¸ë‹¬', 'ì‡¼í¬', 'ë§¤ë„', 'ë¶ˆì•ˆ', 'ìœ„ê¸°', 'ë¦¬ìŠ¤í¬']
    
    try:
        res = requests.get(url, headers=HEADERS, timeout=5)
        res.raise_for_status()
        data = json.loads(res.content.decode('utf-8', 'ignore'))
        
        headlines = []
        for group in data:
            for item in group.get('items', []):
                title = item.get('title', '')
                if title:
                    title = title.replace('&quot;', '"').replace('&lt;', '<').replace('&gt;', '>')
                    headlines.append(title)
                    if len(headlines) >= 15:
                        break
            if len(headlines) >= 15:
                break
                
        pos_count = 0
        neg_count = 0
        neutral_count = 0
        analyzed_news = []
        
        for title in headlines:
            is_pos = any(kw in title for kw in pos_keywords)
            is_neg = any(kw in title for kw in neg_keywords)
            
            if is_pos and not is_neg:
                sentiment = 'positive'
                pos_count += 1
            elif is_neg and not is_pos:
                sentiment = 'negative'
                neg_count += 1
            else:
                sentiment = 'neutral'
                neutral_count += 1
                
            analyzed_news.append({"title": title, "sentiment": sentiment})
            
        total = len(headlines)
        if total == 0:
            return None
            
        return {
            "total": total,
            "positive_ratio": round((pos_count / total) * 100),
            "negative_ratio": round((neg_count / total) * 100),
            "neutral_ratio": round((neutral_count / total) * 100),
            "pos_count": pos_count,
            "neg_count": neg_count,
            "neutral_count": neutral_count,
            "news_list": analyzed_news
        }
    except Exception as e:
        print(f"Error fetching news sentiment: {e}")
        return None



@app.get("/review", response_class=HTMLResponse)
async def read_review(request: Request, ticker: str = "005930"): # ê¸°ë³¸ê°’: ì‚¼ì„±ì „ì
    search_name = ticker.strip()
    actual_ticker = resolve_ticker(search_name)
    
    context = {"ticker": actual_ticker, "search_name": search_name, "error": None, "chart_data": None, "ai_score": None, "fundamentals": None, "sentiment_data": None}
    
    try:
        # ìµœê·¼ 6ê°œì›” ë°ì´í„° ë¡œë“œ
        end_date = datetime.now()
        start_date = end_date - pd.DateOffset(months=6)
        
        # DataFrame ë¡œì»¬ ë³€ìˆ˜
        df = fdr.DataReader(actual_ticker, start_date, end_date)
        if df.empty:
            context["error"] = "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢…ëª© ì½”ë“œë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
            return templates.TemplateResponse(request=request, name="review.html", context=context)
            
        df = calculate_technical_indicators(df)
        df = df.dropna() # ì§€í‘œ ê³„ì‚° í›„ NaN ì œê±°
        
        # ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ì²˜ë¦¬
        df.reset_index(inplace=True)
        if 'Date' in df.columns:
            df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
            
        # JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ dict ë³€í™˜
        records = df.to_dict('records')
        context["chart_data"] = json.dumps(records)
        
        # --- AI í€€íŠ¸ ì¢…í•© ë¶„ì„ (ë¡œì§ í¬íŒ…) ---
        last_row = df.iloc[-1]
        score = 50
        
        # ì´ë™í‰ê·  ì •ë°°ì—´/ì—­ë°°ì—´ ê°€ì 
        if last_row['MA5'] > last_row['MA20'] > last_row['MA60']: score += 20
        elif last_row['MA5'] < last_row['MA20'] < last_row['MA60']: score -= 20
            
        # RSI ì ìˆ˜ ë¡œì§ (ê³ ê¸‰)
        current_rsi = last_row['RSI']
        if current_rsi < 30: score += 15 # ê³¼ë§¤ë„ (ë°˜ë“± ê¸°ëŒ€)
        elif current_rsi > 70: score -= 15 # ê³¼ë§¤ìˆ˜ (ì¡°ì • ìš°ë ¤)
        elif 40 <= current_rsi <= 60: score += 5 # ì•ˆì •ì  ì¶”ì„¸
        
        # ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜ (3í‘œì¤€í¸ì°¨ í¬í•¨)
        current_price = last_row['Close']
        if current_price < last_row['BB_LOWER_EXT']: score += 25 # ê·¹ë‹¨ì  í•˜ë‹¨ ì´íƒˆ (ê°•í•œ ë¬¼íƒ€ê¸°/ë§¤ìˆ˜)
        elif current_price < last_row['BB_LOWER']: score += 10 # ë°´ë“œ í•˜ë‹¨ ì´íƒˆ (ë‹¨ê¸° ë°˜ë“±)
        elif current_price > last_row['BB_UPPER_EXT']: score -= 25 # ê·¹ë‹¨ì  ìƒë‹¨ ì´íƒˆ (ê°•í•œ ì°¨ìµì‹¤í˜„)
        elif current_price > last_row['BB_UPPER']: score -= 10 # ë°´ë“œ ìƒë‹¨ ëŒíŒŒ (ê³¼ì—´)
        elif current_price > last_row['MA5']: score += 5 # ë‹¨ê¸° ì´í‰ì„  ì§€ì§€
            
        # ì ìˆ˜ ì •ê·œí™” (0~100)
        final_score = max(0, min(100, score))
        
        # ì‹œë‚˜ë¦¬ì˜¤ ë§¤í•‘
        if final_score >= 80: phase_text = "ê·¹ë‹¨ì  ê³¼ë§¤ë„ (ê¸°ìˆ ì  ë°˜ë“± ê°€ëŠ¥ì„± êµ¬ê°„)"
        elif final_score >= 60: phase_text = "ìƒìŠ¹ ì¶”ì„¸ (í™€ë”© ë° ë¶„í•  ë§¤ìˆ˜)"
        elif final_score >= 40: phase_text = "ì¤‘ë¦½/ë°•ìŠ¤ê¶Œ (ê´€ë§)"
        elif final_score >= 20: phase_text = "í•˜ë½ ì¶”ì„¸ (ì‹ ê·œ ë§¤ìˆ˜ ë³´ë¥˜)"
        else: phase_text = "ê·¹ë‹¨ì  ê³¼ë§¤ìˆ˜ (í˜„ê¸ˆí™”/ìµì ˆ íƒ€ì )"
            
        context["ai_score"] = {
            "score": round(final_score),
            "phase": phase_text,
            "rsi": round(current_rsi, 2)
        }
        
        # í€ë”ë©˜í„¸ ë°ì´í„° ìˆ˜ì§‘ ê²°í•©
        context["fundamentals"] = get_stock_fundamentals(actual_ticker)
        
        # ë‰´ìŠ¤ ì„¼í‹°ë©˜íŠ¸ ë¶„ì„ ê²°í•©
        context["sentiment_data"] = get_news_sentiment(actual_ticker)
        
        return templates.TemplateResponse(request=request, name="review.html", context=context)
            
    except Exception as e:
        context["error"] = f"ì—ëŸ¬ ë°œìƒ: {e}"

    return templates.TemplateResponse(request=request, name="review.html", context=context)

# ---------------------------------------------------------
# Tab 5 & 6 equivalents: Portfolio and Alerts (Form Handlers)
# ---------------------------------------------------------

@app.get("/portfolio", response_class=HTMLResponse)
async def read_portfolio(request: Request):
    context = {"error": None}
    return templates.TemplateResponse(request=request, name="portfolio.html", context=context)
    
@app.get("/policies", response_class=HTMLResponse)
async def read_policies(request: Request):
    # Legal Policies and AdSense Guide
    return templates.TemplateResponse(request=request, name="policies.html", context={})

# --- API Endpoints for DB CRUD & Auth ---
@app.post("/api/register") # Removed response_model to prevent validation error when returning a dict
def register_user(user: schemas.UserCreate, db: Session = Depends(get_db)):
    db_user = db.query(models.User).filter(models.User.username == user.username).first()
    if db_user:
        raise HTTPException(status_code=400, detail="Username already registered")
    
    hashed_password = auth.get_password_hash(user.password)
    # By default, we grant premium for testing. In prod, this is triggered by payment.
    db_user = models.User(username=user.username, hashed_password=hashed_password, membership="premium")
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
    return {"message": "User registered successfully"}

@app.post("/api/token")
def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):
    user = db.query(models.User).filter(models.User.username == form_data.username).first()
    if not user or not auth.verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    access_token_expires = auth.timedelta(minutes=auth.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": user.username}, expires_delta=access_token_expires
    )
    return {"access_token": access_token, "token_type": "bearer", "membership": user.membership}

@app.post("/api/portfolio", response_model=schemas.Portfolio)
def add_portfolio_item(item: schemas.PortfolioCreate, db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    db_item = models.Portfolio(
        ticker=item.ticker,
        target_price=item.target_price,
        user_id=current_user.id
    )
    db.add(db_item)
    db.commit()
    db.refresh(db_item)
    return db_item

@app.get("/api/portfolio")
def get_portfolio_items(db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    items = db.query(models.Portfolio).filter(models.Portfolio.user_id == current_user.id).all()
    # Mocking qty for now in response to match frontend expectations
    return [{"id": i.id, "name": i.ticker, "price": i.target_price or 0, "qty": 1} for i in items]

@app.delete("/api/portfolio/{item_id}")
def delete_portfolio_item(item_id: int, db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    item = db.query(models.Portfolio).filter(models.Portfolio.id == item_id, models.Portfolio.user_id == current_user.id).first()
    if item:
        db.delete(item)
        db.commit()
        return {"status": "success"}
    raise HTTPException(status_code=404, detail="Item not found")

# --- Google AdSense ads.txt ì¸ì¦ ìš°íšŒ ë¼ìš°íŠ¸ ---
@app.get("/ads.txt", response_class=PlainTextResponse)
async def get_ads_txt():
    # ìº¡ì²˜ í™”ë©´ì—ì„œ í™•ì¸í•œ ë³¸ì¸ì˜ pub IDë¥¼ ì ìš©í•œ ê³µì‹ ì¸ì¦ í…ìŠ¤íŠ¸
    return "google.com, pub-9065075656013134, DIRECT, f08c47fec0942fa0"

if __name__ == "__main__":
    import uvicorn
    # Make sure to run the app with 'uvicorn main:app --reload' in production
    uvicorn.run(app, host="127.0.0.1", port=8000)
